{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161900dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo_inference.ipynb\n",
    "\n",
    "# ===========================================================\n",
    "# 1. Imports & Setup\n",
    "# ===========================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Import your modules (adjust these imports if your paths are different)\n",
    "from src.dataset import CustomImageDataset\n",
    "from src.model_resnet50 import MultiscaleFusionClassifier  # <-- choose your model class\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. Set Paths & Parameters\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "DATA_DIR = \"./data\"\n",
    "MODEL_CKPT = \"./outputs/mhgf2/best_model_fold1.pth\"  # Change to your path/backbone\n",
    "TEST_META_CSV = os.path.join(DATA_DIR, \"padufes20/padufes20-test-metadata.csv\")\n",
    "TEST_IMG_DIR = os.path.join(DATA_DIR, \"padufes20/padufes20-test-set\")\n",
    "BATCH_SIZE = 8  # For demo, keep small\n",
    "\n",
    "# Feature columns (copy from your code)\n",
    "cols = [\n",
    "    'age', 'smoke', 'drink', 'pesticide', 'gender', 'skin_cancer_history',\n",
    "    'cancer_history', 'has_piped_water', 'has_sewage_system',\n",
    "    'background_father_10', 'background_father_12', 'background_father_2',\n",
    "    'background_father_4', 'background_father_6', 'background_father_7',\n",
    "    'background_father_9', 'background_father_Other', 'background_mother_0',\n",
    "    'background_mother_10', 'background_mother_2', 'background_mother_3',\n",
    "    'background_mother_4', 'background_mother_7', 'background_mother_8',\n",
    "    'background_mother_Other', 'region_0', 'region_1', 'region_10',\n",
    "    'region_11', 'region_12', 'region_13', 'region_2', 'region_3',\n",
    "    'region_4', 'region_5', 'region_6', 'region_7', 'region_8', 'region_9',\n",
    "    'itch_1.0', 'grew_1.0', 'hurt_1.0', 'changed_1.0', 'bleed_1.0',\n",
    "    'elevation_1.0', 'fitspatrick'\n",
    "]\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. Load Data (Test Set)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "test_df = pd.read_csv(TEST_META_CSV)\n",
    "test_img_paths = [os.path.join(TEST_IMG_DIR, f\"{img_id}.png\") for img_id in test_df.img_id]\n",
    "test_labels = test_df.diagnostic_encoded.values\n",
    "test_meta = test_df[cols].values\n",
    "\n",
    "# Define image transforms (same as validation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create dataset and loader\n",
    "demo_ds = CustomImageDataset(test_img_paths, test_meta, test_labels, transform=val_transform)\n",
    "demo_ld = DataLoader(demo_ds, batch_size=BATCH_SIZE, shuffle=True)  # shuffle=True to get random batch\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4. Load Model and Weights\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Model params (update if needed to match your training)\n",
    "num_classes = len(np.unique(test_labels))\n",
    "meta_in = test_meta.shape[1]\n",
    "meta_out = 768\n",
    "K_init = [8, 8, 8]\n",
    "ref_delta = 4\n",
    "ref_epochs = [50, 100, 150]\n",
    "\n",
    "model = MultiscaleFusionClassifier(num_classes, meta_in, meta_out, K_init, ref_delta, ref_epochs)\n",
    "model.load_state_dict(torch.load(MODEL_CKPT, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded from:\", MODEL_CKPT)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5. Inference on a Batch\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_imgs, batch_meta, batch_labels = next(iter(demo_ld))\n",
    "    batch_imgs, batch_meta = batch_imgs.to(device), batch_meta.to(device)\n",
    "    logits = model(batch_imgs, batch_meta)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "print(\"Ground truth labels:\", batch_labels.tolist())\n",
    "print(\"Predicted labels:   \", preds.cpu().tolist())\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 6. Show Images with Predictions\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class_names = {0: \"BCC\", 1: \"SCC\", 2: \"ACK\", 3: \"NEV\", 4: \"MEL\", 5: \"SEK\"}  # update as needed\n",
    "\n",
    "def plot_images(images, labels, preds, probs, class_names, max_images=8):\n",
    "    n = min(len(images), max_images)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(n):\n",
    "        img = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        gt = class_names.get(labels[i].item(), str(labels[i].item()))\n",
    "        pr = class_names.get(preds[i].item(), str(preds[i].item()))\n",
    "        plt.title(f\"GT:{gt}\\nPR:{pr}\\nConf:{probs[i][preds[i]].item():.2f}\", fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_images(batch_imgs, batch_labels, preds, probs, class_names)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 7. Confusion Matrix on the Whole Test Set (optional)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# For a quick demo, you can run on a small test subset. For full results, set batch_size larger and iterate.\n",
    "all_gt, all_pr = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, meta, labels in DataLoader(demo_ds, batch_size=32):\n",
    "        imgs, meta = imgs.to(device), meta.to(device)\n",
    "        logits = model(imgs, meta)\n",
    "        pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_gt.extend(labels.numpy())\n",
    "        all_pr.extend(pred)\n",
    "\n",
    "cm = confusion_matrix(all_gt, all_pr)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[class_names.get(i, str(i)) for i in range(num_classes)])\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "disp.plot(ax=ax, cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpu2)",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
